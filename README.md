<div>
  <h2 align="center">A Hybrid Arabic Text Summarization Approach based on Transformers</h2>
</div>

[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)

### Abstract :
In this paper, we proposed a sequential hybrid model based on a transformer to summarize Arabic articles. We used two approaches of summarization to make our model. The First is the extractive approach which depends on the most important sentences from the articles to be the summary, so we used Deep Learning techniques specifically transformers such as AraBert to make our summary, The second is abstractive, and this approach is similar to human summarization, which means that it can use some words which have the same meaning but different from the original text. We apply this kind of summary using MT5 Arabic pre-trained transformer model. We sequentially applied these two summarization approaches to building our A3SUT hybrid model. The output of the extractive module is fed into the abstractive module. We enhanced the summaryâ€™s quality to be closer to the human summary by applying this approach. 
We add some features to our summary to make it more understandable by applying the metadata generation task "data about data" and classification. By applying metadata generation, we add facilities to our summary, identification, and summary organization.

### IEEE Paper Link :

### Proposed Model :

### Data Provided in Data Folder :
<ul>
  <li>EASC ( Extractive Summarization Dataset )</li>
  <li>NADA Corpus ( Text Classification Dataset )</li>
</ul>

### Running The Project :

### Contributers :
<ul>
  <li>Mohamed Ehab</li>
  <li>Ameen Reda</li>
  <li>John Adel</li>
  <li>Ismail Ahmed</li>
  <li>Mostafa Kafafy</li>
  <li>Nada Salah</li>
  <li>Dr. Ghada Khoriba</li>
</ul>

<div>
  <h2 align="center">Feel Free to Contact us</h2>
</div>
